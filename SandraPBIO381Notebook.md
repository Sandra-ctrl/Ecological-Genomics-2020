# Title  

## Author: Sandra Nnadi 
### Affiliation:  PhD Student
### E-mail contact: sandra.nnadi@uvm.edu


### Start Date: 2020-01-13
### End Date: 2020-05-08
### Project Descriptions:   





# Table of Contents:   
* [Entry 1: 2020-01-13, Monday](#id-section1)
* [Entry 2: 2020-01-14, Tuesday](#id-section2)
* [Entry 3: 2020-01-15, Wednesday](#id-section3)
* [Entry 4: 2020-01-16, Thursday](#id-section4)
* [Entry 5: 2020-01-17, Friday](#id-section5)
* [Entry 6: 2020-01-20, Monday](#id-section6)
* [Entry 7: 2020-01-21, Tuesday](#id-section7)
* [Entry 8: 2020-01-22, Wednesday](#id-section8)
* [Entry 9: 2020-01-23, Thursday](#id-section9)
* [Entry 10: 2020-01-24, Friday](#id-section10)
* [Entry 11: 2020-01-27, Monday](#id-section11)
* [Entry 12: 2020-01-28, Tuesday](#id-section12)
* [Entry 13: 2020-01-29, Wednesday](#id-section13)
* [Entry 14: 2020-01-30, Thursday](#id-section14)
* [Entry 15: 2020-01-31, Friday](#id-section15)
* [Entry 16: 2020-02-03, Monday](#id-section16)
* [Entry 17: 2020-02-04, Tuesday](#id-section17)
* [Entry 18: 2020-02-05, Wednesday](#id-section18)
* [Entry 19: 2020-02-06, Thursday](#id-section19)
* [Entry 20: 2020-02-07, Friday](#id-section20)
* [Entry 21: 2020-02-10, Monday](#id-section21)
* [Entry 22: 2020-02-11, Tuesday](#id-section22)
* [Entry 23: 2020-02-12, Wednesday](#id-section23)
* [Entry 24: 2020-02-13, Thursday](#id-section24)
* [Entry 25: 2020-02-14, Friday](#id-section25)
* [Entry 26: 2020-02-17, Monday](#id-section26)
* [Entry 27: 2020-02-18, Tuesday](#id-section27)
* [Entry 28: 2020-02-19, Wednesday](#id-section28)
* [Entry 29: 2020-02-20, Thursday](#id-section29)
* [Entry 30: 2020-02-21, Friday](#id-section30)
* [Entry 31: 2020-02-24, Monday](#id-section31)
* [Entry 32: 2020-02-25, Tuesday](#id-section32)
* [Entry 33: 2020-02-26, Wednesday](#id-section33)
* [Entry 34: 2020-02-27, Thursday](#id-section34)
* [Entry 35: 2020-02-28, Friday](#id-section35)
* [Entry 36: 2020-03-02, Monday](#id-section36)
* [Entry 37: 2020-03-03, Tuesday](#id-section37)
* [Entry 38: 2020-03-04, Wednesday](#id-section38)
* [Entry 39: 2020-03-05, Thursday](#id-section39)
* [Entry 40: 2020-03-06, Friday](#id-section40)
* [Entry 41: 2020-03-09, Monday](#id-section41)
* [Entry 42: 2020-03-10, Tuesday](#id-section42)
* [Entry 43: 2020-03-11, Wednesday](#id-section43)
* [Entry 44: 2020-03-12, Thursday](#id-section44)
* [Entry 45: 2020-03-13, Friday](#id-section45)
* [Entry 46: 2020-03-16, Monday](#id-section46)
* [Entry 47: 2020-03-17, Tuesday](#id-section47)
* [Entry 48: 2020-03-18, Wednesday](#id-section48)
* [Entry 49: 2020-03-19, Thursday](#id-section49)
* [Entry 50: 2020-03-20, Friday](#id-section50)
* [Entry 51: 2020-03-23, Monday](#id-section51)
* [Entry 52: 2020-03-24, Tuesday](#id-section52)
* [Entry 53: 2020-03-25, Wednesday](#id-section53)
* [Entry 54: 2020-03-26, Thursday](#id-section54)
* [Entry 55: 2020-03-27, Friday](#id-section55)
* [Entry 56: 2020-03-30, Monday](#id-section56)
* [Entry 57: 2020-03-31, Tuesday](#id-section57)
* [Entry 58: 2020-04-01, Wednesday](#id-section58)
* [Entry 59: 2020-04-02, Thursday](#id-section59)
* [Entry 60: 2020-04-03, Friday](#id-section60)
* [Entry 61: 2020-04-06, Monday](#id-section61)
* [Entry 62: 2020-04-07, Tuesday](#id-section62)
* [Entry 63: 2020-04-08, Wednesday](#id-section63)
* [Entry 64: 2020-04-09, Thursday](#id-section64)
* [Entry 65: 2020-04-10, Friday](#id-section65)
* [Entry 66: 2020-04-13, Monday](#id-section66)
* [Entry 67: 2020-04-14, Tuesday](#id-section67)
* [Entry 68: 2020-04-15, Wednesday](#id-section68)
* [Entry 69: 2020-04-16, Thursday](#id-section69)
* [Entry 70: 2020-04-17, Friday](#id-section70)
* [Entry 71: 2020-04-20, Monday](#id-section71)
* [Entry 72: 2020-04-21, Tuesday](#id-section72)
* [Entry 73: 2020-04-22, Wednesday](#id-section73)
* [Entry 74: 2020-04-23, Thursday](#id-section74)
* [Entry 75: 2020-04-24, Friday](#id-section75)
* [Entry 76: 2020-04-27, Monday](#id-section76)
* [Entry 77: 2020-04-28, Tuesday](#id-section77)
* [Entry 78: 2020-04-29, Wednesday](#id-section78)
* [Entry 79: 2020-04-30, Thursday](#id-section79)
* [Entry 80: 2020-05-01, Friday](#id-section80)
* [Entry 81: 2020-05-04, Monday](#id-section81)
* [Entry 82: 2020-05-05, Tuesday](#id-section82)
* [Entry 83: 2020-05-06, Wednesday](#id-section83)
* [Entry 84: 2020-05-07, Thursday](#id-section84)
* [Entry 85: 2020-05-08, Friday](#id-section85)


------    
<div id='id-section1'/>   


### Entry 1: 2020-01-13, Monday.   



------    
<div id='id-section2'/>   


### Entry 2: 2020-01-14, Tuesday.   



------    
<div id='id-section3'/>   


### Entry 3: 2020-01-15, Wednesday.   



------    
<div id='id-section4'/>   


### Entry 4: 2020-01-16, Thursday.   



------    
<div id='id-section5'/>   


### Entry 5: 2020-01-17, Friday.   



------    
<div id='id-section6'/>   


### Entry 6: 2020-01-20, Monday.   



------    
<div id='id-section7'/>   


### Entry 7: 2020-01-21, Tuesday.   



------    
<div id='id-section8'/>   


### Entry 8: 2020-01-22, Wednesday.   



------    
<div id='id-section9'/>   


### Entry 9: 2020-01-23, Thursday.   



------    
<div id='id-section10'/>   


### Entry 10: 2020-01-24, Friday.   



------    
<div id='id-section11'/>   


### Entry 11: 2020-01-27, Monday.   
* Created notebook
* downloaded the template from Lauren
* copied the template
* pasted template on This PC/Documents/Github/Ecological -Genomics 2020
* committed the template
* pushed the template from Github desktop to Github browser
* viewed template on github browser
* edited the entry for Mon 27

```
cd  ~/mydata
ls
```
* edited assignment on command line tutorial

```
pwd
ls
git clone https://github.com/Sandra-ctrl/Ecological-Genomics-2020
cd Ecological-Genomics-2020/
ll
mkdir mydata
ll
mkdir myscripts
mkdir myresults
ll
cd /data/project_data/RS_ExomeSeq
ll
cd metadata
ll
cp RS_Exome_metadata.txt ~/Ecological-Genomics-2020// mydata/
cd ~/Ecological-Genomics-2020/mydata/
ll
head RS_Exome_metadata.txt
grep -w "E" RS_Exome_metadata.txt |wc
grep -w "E" RS_Exome_metadata.txt >Edge_only.txt
ls
man grep
grep -w "E" RS_Exome_metadata.txt | wc -l
grep -w "E" RS_Exome_metadata.txt |cut -f1 | uniq
grep -w "E" RS_Exome_metadata.txt |cut -f1 | uniq |wc -l
grep -w "E" RS_Exome_metadata.txt |cut -f1 | uniq >EdgePops.txt
ll
mkdir metadata
mv *txt metadata/
ll metadata/
cd metadata/
grep -w "AB" RS_Exome_metadata.txt >AB.txt
ll
rm AB.txt
ll
ll -a
vim .bashrc
cd Ecological-Genomics-2020
git pull
git add --all
git commit -m "syncing server with current repo"
git push
exit

```

------    
<div id='id-section12'/>   


### Entry 12: 2020-01-28, Tuesday.   



------    
<div id='id-section13'/>   


### Entry 13: 2020-01-29, Wednesday.   
POPGEN Day 1 Objectives
* To get background on the ecology of Red spruce (Picea rubens), and the experimental design of the exome capture data
* To understand the general work flow or “pipeline” for processing and analyzing the exome capture sequence data
* To visualize and interpret Illumina data quality (what is a fastq file; what are Phred scores?).
* To learn how to make/write a bash script, and how to use bash commands to process files in batches
* To trim the reads based on base quality scores
* To start mapping (a.k.a. aligning) each set of cleaned reads to a reference genome

difference between .Rmd and .md
.Rmd allows the ability to execute R code within R while .md allows any file on github ending with .md look nice. 
# creates a header
## increases the font
### makes font bigger
 * (space) to create bullets
 [ } to create weblink
 e.g [genomics is cool] (http://...com)
 
 embedding code with back tick
 ```
 cd ~/mydata
 ll
 ```
 will give you a code block
 
 introduction to Red Spruce. details found in tutorial.
 current red spruce species are at the limit of migration thus making them vulnerable to climate change
 Steve Keller team are studying the genetic basis of climate adaptation using exome data and a retrospective approach. 
 
# The Pipeline
Visualize, Clean, Visualize
* Visualize the quality of raw data (Program: FastQC)

* Clean raw data (Program: Trimmomatic)

* Visualize the quality of cleaned data (Program: FastQC)

Calculate #’s of cleaned, high quality reads going into mapping

Map (a.k.a. Align) cleaned reads from each sample to the reference assembly to generate sequence alignment files (Program: bwa, Input: .fastq, Output: .sam).

Remove PCR duplicates identified during mapping, and calculate alignment statistics (% of reads mapping succesully, mapping quality scores, average depth of coverage per individual)
 
```
cd /data/project_data/RS_ExomeSeq/fastq/edge_fastq
ll
zcat AB_05_R1_fastq.gz | head -n 4
```
@GWNJ-0842:368:GW1809211440:2:1101:17168:1907 1:N:0:NGAAGAGA+NTTCGCCT
GATGGGATTAGAGCCCCTGAAGGCTGATAGAACTTGAGTTTCACAGGCTCATTGCATTGAAGTGGCATTTGTGTGAATGCAGAGGAGGTACATAGGTCCTCGAGAATAAAAGAGATGTTGCTCCTCACCAAAATCAGTACAGATTATTTT
+
A<A-F<AFJFJFJA7FJJJJFFJJJJJJ<AJ-FJJ7-A-FJAJJ-JJJA7A7AFJ<FF--<FF7-AJJFJFJA-<A-FAJ<AJJ<JJF--<A-7F-777-FA77---7AJ-JF-FJF-A--AJF-7FJFF77F-A--7<-F--77<JFF<

line 1	Always begins with ‘@’ and then information about the read
line 2	The actual DNA sequence
line 3	Always begins with a ‘+’ and sometimes the same info in line 1
line 4	A string of characters which represent the quality scores; always has same number of characters as line 2

If P is the probability that a base call is an error, then:

P = 10^(–Q/10)

Q = –10 log10(P)

So:

Phred Quality Score	      Probability of incorrect base call	       Base call accuracy
10	                                1 in 10	                               90%
20	                                1 in 100	                              99%
30	                                1 in 1000	                             99.9%
40	                                1 in 10,000	                           99.99%

The Phred Q score is translated to ASCII characters so that a two digit number can be represented by a single character.

 Quality encoding: !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHI
                   |         |         |         |         |
    Quality score: 0........10........20........30........40 
    
```
mkdir ~/Ecological-Genomics-2020/myresults/fastqc
fastqc FILENAME.fastq.gz -o outputdirectory/
vim
for file in KOS*fastq.gz

do

 fastqc ${file} -o ~/<Ecological-Genomics-2020/myresults/fastqc

done
ll
```
to change permission on script to make it executable

```
chmod u+x fastqc.sh
./fastqc.sh
```
chmod u+x fastqc.sh    # makes the script "executable" by the "user"
./fastqc.sh             # executes the script

there was a little error with the location of the fastqc/ file. i could not locate it in the myresults folder, so i did the following

```
cd myresults
mkdir fastqc
cd fastqc
mv ~/Ecological-Genomics-2020/myscripts/fastqc/* 
ll
git pull
git add --all
git commit -m "syncing server with fastqc repo"
git push

```
# clean using trimmomatic
Copy the bash script over to your ~/myrepo/myscripts directory
Open and edit the bash script using the program vim.
Edit the file so that you’re trimming the fastq files for the population assigned to you
Change the permissions on your script to make it executable, then run it! (examples below)
cp /data/scripts/trim_loop.sh  ~/myrepo/myscripts/ 
# copies the script to your home scripts dir
vim trim_loop.sh    # open the script with vim to edit

```
cp /data/scripts/trim_loop.sh  ~/Ecological-Genomics-2020/myscripts/
vim trim_loop.sh
bash trim_loop.sh

```
This time we use the variable coding to call the name of the R1 read pair, define the name for the second read in the pair (R2), and create a basename that only contains the “pop_ind” part of the name, i.e. AB_05

    R2=${R1/_R1_fastq.gz/_R2_fastq.gz}   # defines the name for the second read in the pair (R2) based on knowing the R1 name (the file names are identifcal except for the R1 vs. R2 designation)
    f=${R1/_R1_fastq.gz/}   # creates a new variable from R1 that has the "_R1_fastq.gz" stripped off
    name=`basename ${f}`   # calls the handy "basename" function to define a new variable containing only the very last part of the filename while stripping off all the path information.  This gets us the "AB_05" bit we want.

Here’s how it should look (replace AB with your population name):

#!/bin/bash   
 
cd /data/project_data/RS_ExomeSeq/fastq/edge_fastq  

for R1 in AB*R1_fastq.gz  

do 
 
    R2=${R1/_R1_fastq.gz/_R2_fastq.gz}
    f=${R1/_R1_fastq.gz/}
    name=`basename ${f}`

    java -classpath /data/popgen/Trimmomatic-0.33/trimmomatic-0.33.jar org.usadellab.trimmomatic.TrimmomaticPE \
        -threads 1 \
        -phred33 \
         "$R1" \
         "$R2" \
         /data/project_data/RS_ExomeSeq/fastq/edge_fastq/pairedcleanreads/${name}_R1.cl.pd.fq \
         /data/project_data/RS_ExomeSeq/fastq/edge_fastq/unpairedcleanreads/${name}_R1.cl.un.fq \
         /data/project_data/RS_ExomeSeq/fastq/edge_fastq/pairedcleanreads/${name}_R2.cl.pd.fq \
         /data/project_data/RS_ExomeSeq/fastq/edge_fastq/unpairedcleanreads/${name}_R2.cl.un.fq \
        ILLUMINACLIP:/data/popgen/Trimmomatic-0.33/adapters/TruSeq3-PE.fa:2:30:10 \
        LEADING:20 \
        TRAILING:20 \
        SLIDINGWINDOW:6:20 \
        MINLEN:35 
 
done 

ILLUMINACLIP: Cut adapter and other illumina-specific sequences from the read.
LEADING: Cut bases off the start of a read, if below a threshold quality
TRAILING: Cut bases off the end of a read, if below a threshold quality
SLIDINGWINDOW: Perform a sliding window trimming, cutting once the average quality within the window falls below a threshold.
MINLEN: Drop the read if it is below a specified length

```
cd /data/project_data/RS_ExomeSeq/fastq/edge_fastq/pairedcleanreads/
ll /data/project_data/RS_ExomeSeq/fastq/edge_fastq/pairedcleanreads/ | wc -l
cd ~/
exit

```




------    
<div id='id-section14'/>   


### Entry 14: 2020-01-30, Thursday.   



------    
<div id='id-section15'/>   


### Entry 15: 2020-01-31, Friday.   



------    
<div id='id-section16'/>   


### Entry 16: 2020-02-03, Monday.   



------    
<div id='id-section17'/>   


### Entry 17: 2020-02-04, Tuesday.   



------    
<div id='id-section18'/>   


### Entry 18: 2020-02-05, Wednesday.   



------    
<div id='id-section19'/>   


### Entry 19: 2020-02-06, Thursday.   



------    
<div id='id-section20'/>   


### Entry 20: 2020-02-07, Friday.   



------    
<div id='id-section21'/>   


### Entry 21: 2020-02-10, Monday.   



------    
<div id='id-section22'/>   


### Entry 22: 2020-02-11, Tuesday.   



------    
<div id='id-section23'/>   


### Entry 23: 2020-02-12, Wednesday.   



------    
<div id='id-section24'/>   


### Entry 24: 2020-02-13, Thursday.   



------    
<div id='id-section25'/>   


### Entry 25: 2020-02-14, Friday.   



------    
<div id='id-section26'/>   


### Entry 26: 2020-02-17, Monday.   



------    
<div id='id-section27'/>   


### Entry 27: 2020-02-18, Tuesday.   



------    
<div id='id-section28'/>   


### Entry 28: 2020-02-19, Wednesday.   



------    
<div id='id-section29'/>   


### Entry 29: 2020-02-20, Thursday.   



------    
<div id='id-section30'/>   


### Entry 30: 2020-02-21, Friday.   



------    
<div id='id-section31'/>   


### Entry 31: 2020-02-24, Monday.   



------    
<div id='id-section32'/>   


### Entry 32: 2020-02-25, Tuesday.   



------    
<div id='id-section33'/>   


### Entry 33: 2020-02-26, Wednesday.   



------    
<div id='id-section34'/>   


### Entry 34: 2020-02-27, Thursday.   



------    
<div id='id-section35'/>   


### Entry 35: 2020-02-28, Friday.   



------    
<div id='id-section36'/>   


### Entry 36: 2020-03-02, Monday.   



------    
<div id='id-section37'/>   


### Entry 37: 2020-03-03, Tuesday.   



------    
<div id='id-section38'/>   


### Entry 38: 2020-03-04, Wednesday.   



------    
<div id='id-section39'/>   


### Entry 39: 2020-03-05, Thursday.   



------    
<div id='id-section40'/>   


### Entry 40: 2020-03-06, Friday.   



------    
<div id='id-section41'/>   


### Entry 41: 2020-03-09, Monday.   



------    
<div id='id-section42'/>   


### Entry 42: 2020-03-10, Tuesday.   



------    
<div id='id-section43'/>   


### Entry 43: 2020-03-11, Wednesday.   



------    
<div id='id-section44'/>   


### Entry 44: 2020-03-12, Thursday.   



------    
<div id='id-section45'/>   


### Entry 45: 2020-03-13, Friday.   



------    
<div id='id-section46'/>   


### Entry 46: 2020-03-16, Monday.   



------    
<div id='id-section47'/>   


### Entry 47: 2020-03-17, Tuesday.   



------    
<div id='id-section48'/>   


### Entry 48: 2020-03-18, Wednesday.   



------    
<div id='id-section49'/>   


### Entry 49: 2020-03-19, Thursday.   



------    
<div id='id-section50'/>   


### Entry 50: 2020-03-20, Friday.   



------    
<div id='id-section51'/>   


### Entry 51: 2020-03-23, Monday.   



------    
<div id='id-section52'/>   


### Entry 52: 2020-03-24, Tuesday.   



------    
<div id='id-section53'/>   


### Entry 53: 2020-03-25, Wednesday.   



------    
<div id='id-section54'/>   


### Entry 54: 2020-03-26, Thursday.   



------    
<div id='id-section55'/>   


### Entry 55: 2020-03-27, Friday.   



------    
<div id='id-section56'/>   


### Entry 56: 2020-03-30, Monday.   



------    
<div id='id-section57'/>   


### Entry 57: 2020-03-31, Tuesday.   



------    
<div id='id-section58'/>   


### Entry 58: 2020-04-01, Wednesday.   



------    
<div id='id-section59'/>   


### Entry 59: 2020-04-02, Thursday.   



------    
<div id='id-section60'/>   


### Entry 60: 2020-04-03, Friday.   



------    
<div id='id-section61'/>   


### Entry 61: 2020-04-06, Monday.   



------    
<div id='id-section62'/>   


### Entry 62: 2020-04-07, Tuesday.   



------    
<div id='id-section63'/>   


### Entry 63: 2020-04-08, Wednesday.   



------    
<div id='id-section64'/>   


### Entry 64: 2020-04-09, Thursday.   



------    
<div id='id-section65'/>   


### Entry 65: 2020-04-10, Friday.   



------    
<div id='id-section66'/>   


### Entry 66: 2020-04-13, Monday.   



------    
<div id='id-section67'/>   


### Entry 67: 2020-04-14, Tuesday.   



------    
<div id='id-section68'/>   


### Entry 68: 2020-04-15, Wednesday.   



------    
<div id='id-section69'/>   


### Entry 69: 2020-04-16, Thursday.   



------    
<div id='id-section70'/>   


### Entry 70: 2020-04-17, Friday.   



------    
<div id='id-section71'/>   


### Entry 71: 2020-04-20, Monday.   



------    
<div id='id-section72'/>   


### Entry 72: 2020-04-21, Tuesday.   



------    
<div id='id-section73'/>   


### Entry 73: 2020-04-22, Wednesday.   



------    
<div id='id-section74'/>   


### Entry 74: 2020-04-23, Thursday.   



------    
<div id='id-section75'/>   


### Entry 75: 2020-04-24, Friday.   



------    
<div id='id-section76'/>   


### Entry 76: 2020-04-27, Monday.   



------    
<div id='id-section77'/>   


### Entry 77: 2020-04-28, Tuesday.   



------    
<div id='id-section78'/>   


### Entry 78: 2020-04-29, Wednesday.   



------    
<div id='id-section79'/>   


### Entry 79: 2020-04-30, Thursday.   



------    
<div id='id-section80'/>   


### Entry 80: 2020-05-01, Friday.   



------    
<div id='id-section81'/>   


### Entry 81: 2020-05-04, Monday.   



------    
<div id='id-section82'/>   


### Entry 82: 2020-05-05, Tuesday.   



------    
<div id='id-section83'/>   


### Entry 83: 2020-05-06, Wednesday.   



------    
<div id='id-section84'/>   


### Entry 84: 2020-05-07, Thursday.   



------    
<div id='id-section85'/>   


### Entry 85: 2020-05-08, Friday.   



